import streamlit as st
import whisper
from openai import OpenAI
import tempfile

st.title("Smart Lecture Summarizerr")

# ğŸ”¹ Ø¶Ø¹ Ù…ÙØªØ§Ø­ OpenAI Ù‡Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©
client = OpenAI(api_key="sk-proj-ewlqgXJCEeYWZ1eRququ44s3mdQyUwGMpsPVogr2Pb0JFWJLeGsysBfv9TfmkXhxCtoQmOIXET3BlbkFJmOZdaQKeZw-fv9XWv82zB6EGWSzfLv0ODWpODQDyDj7v-tw1uoG_sIRyoMsbbFHGnd2SZ9oIYA")

# Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
audio_file = st.file_uploader("Upload your lecture audio (mp3, wav, m4a)")

if audio_file:
    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù…Ø¤Ù‚ØªØ§Ù‹
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(audio_file.read())
        tmp_path = tmp.name

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper
    model = whisper.load_model("base")
    result = model.transcribe(tmp_path)
    text = result["text"]

    # Ø²Ø± Ø§Ù„ØªÙ„Ø®ÙŠØµ
    if st.button("Summarize"):
        prompt = f"Summarize this lecture in simple English:\n{text}"

        # Ø·Ù„Ø¨ Ø§Ù„ØªÙ„Ø®ÙŠØµ Ù…Ù† OpenAI GPT
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role":"user","content":prompt}]
        )

        st.subheader("Summary:")
        st.write(response.choices[0].message.content)
